---
title: "Mixed-effects models"
author: "Nicola Roman√≤"
output: 
  tufte::tufte_handout: default
tufte::tufte_html: default
---
  
```{r setup, include=FALSE}
library(tufte)
library(xtable)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(global.par = TRUE)

# See https://stackoverflow.com/questions/25646333/code-chunk-font-size-in-rmarkdown-with-knitr-and-latex
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) 
{
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n\\normalsize"), x)
})

# See https://stackoverflow.com/questions/23349525/how-to-set-knitr-chunk-output-width-on-a-per-chunk-basis
knitr::knit_hooks$set(width=local({
  .width <- 0
  function(before, options, envir) {
    if (before) .width <<- options(width=options$width)
    else options(.width)
  }
}))

```

# Introduction
  
As we have seen in the lectures, both repeated measures and nested designs pose some challenges to data analysis.
In particular, these types of design are problematic as they contain correlated observations.

For example, in the case of a repeated measure design, where we measure a certain parameter in the same subject at different times, each of the measurements is likely to be dependent (thus correlated to some degree) on the previous value.

One of the best ways of dealing with these data is to use mixed effects models, an extension of the linear model that allows to account for random effects into the model.

For the context of this workshop we will need to use the `nlme` R package^[The other commonly used package is `lme4`, with the `lmer` function. The syntax is slightly different but similar reasoning apply]. As usual, this can be installed using the following command:

```{r eval = FALSE}
install.packages("nlme")
```

Installation needs to be performed only once. The package can then be used after loading using:

```{r}
library(nlme)
```

Note: mixed-effects models are quite a complex tool to use. The aim of this workshop is to introduce you to these models, and give you an idea of how to use them for some basic analysis. This is far from being a comprehensive tool^[If you are really interested to expand your knowledge in this area, a very good book is "Mixed Effects Models in S and S-PLUS" by Pinheiro and Bates (this uses S, which is the language R derives from; the S code can be run in R with no major issue)], and analysis of more complex designs may be not so trivial!

# Learning objectives
After completing this workshop you will be able to:

* Creat a mixed effect model to explore simple repeated measure or nested designs.
* Interpret the output of a mixed effect model

# Repeated Measure Design

Let's consider this simple repeated measure design.

We are interested in evaluating the effect of the dopaminergic agonist bromocriptine on the growth of prolactinomas (pituitary adenomas secreting prolactin). We take 45 mice and randomly assign them to one of three groups (15/group).

The control group receives a sham surgery, while the other two groups receive a subcutaneous implant containing either 1 or 10 mg bromocriptine. We then follow the adenoma growth over time by measuring plasma levels of prolactin (PRL).

We have two fixed effects in this design: time and treatment, and a random effect, the mouse. Since each mouse is measured several times, measurements coming from the same animal will not be independent, thus the need for a mixed effect model.

For this example, we start by loading the file `bromocriptine.csv`

```{r}
bromocriptine <- read.csv("bromocriptine.csv")
```

```{r width = 80, size = "small"}
summary(bromocriptine)
```

As usual, explore the data, try to plot it and see possible relationships between variables^[Refer to previous workshops if you do not remember how].

I will also rearrange the order of the levels in the Group factor so that the control group is used as the reference level.

```{r}
bromocriptine$Group <- factor(bromocriptine$Group, 
                              levels = c("CTRL", "Bromo1", "Bromo10"))
```

Below I have plotted the mean PRL values over time in the three groups^[As a challenge, try to reproduce this graph, you may post your code on the discussion board!]

```{r echo = FALSE, fig.height=3.5}
brom.split <- split(bromocriptine, bromocriptine$Group)

mean.brom <- lapply(brom.split, function(x)
      {
      aggregate(x$PRL, by = list(Time=x$Time), FUN=mean)
      })

plot(x ~ Time, mean.brom$CTRL, t = "o", pch = 20,
     bty = "n", ylim = c(0, 600), yaxt = "n",
     xlab = "Time (days)", ylab = "PRL (ng/ml)")

axis(2, seq(0, 600, 200), las = 1)
lines(x ~ Time, mean.brom$Bromo1, t = "o", pch = 2, cex = 0.8)
lines(x ~ Time, mean.brom$Bromo10, t = "o", pch = 5, cex = 0.8)

legend("topleft", c("Control", "Bromocriptine (1 mg)", 
                    "Bromocriptine (10 mg)"), pch = c(20, 2, 5),
       cex = 0.8, bty = "n")
```

It is clear that there is a dose-dependent effect of the drug, and that, overall, the change of PRL levels over time can be studied using a linear model. If we look at the responses of single mice we can see that they start more or less at the same level, but they then rise in different ways (with different slopes) depending on the treatment, but also within the treatment.

```{r echo = FALSE, warning = FALSE, fig.height = 3.2}
library(ggplot2)

ggplot(aes(Time, PRL, group = interaction(Group, Mouse), col = Group),
       data = bromocriptine) + geom_line() +
theme(legend.position="bottom")
```

We can see individual mice differences are not too pronounced at time 0.

```{r, fig.height = 3.5, echo = FALSE}
boxplot(PRL ~ Group, data = bromocriptine, 
        subset = bromocriptine$Time == 0,
        las = 1, pch = 20, ylim = c(0, 50), frame = F)
stripchart(PRL ~ Group, data = bromocriptine,
           subset = bromocriptine$Time == 0,
           las = 1, pch = 20, method = "jitter",
           jitter = 0.1, vertical = TRUE, add = TRUE)
```

Let's now proceed and build our model ^[Remember to load the nlme package first!]. We model the fixed effects Group and Time, as well as their interaction, and we model Mouse as the random factor. We create a random slope model, since what seems to be variable amongst subjects is the slope. We specify the random effect as `Time - 1 | Mouse`, meaning that we want to use mouse as a random effect, and we want to have random slopes over Time but not random intercepts (hence the -1).

```{r, size = "small", width = 80}
model <- lme(PRL ~ Group * Time, data = bromocriptine, 
             random = ~ Time - 1 | Mouse)
summary(model)
```

This is a fairly complex model, the important parts that we want to look at in the summary are:

- AIC, BIC and logLik: these are goodness-of-fit measure. For both AIC and BIC the smaller the better, for the log-likelyhood, the higher the better.
- The random effect part gives us the standard deviations for the random effects and the residuals (remember from the lectures, these derive from two independent normal distribution).
- The fixed effect part gives us the estimates for the model coefficients.
In this case, the intercept 17.23 is the PRL level for a mouse in the control group (because this is the reference level of our Group variable), at time 0. The other coefficients are interpreted as we have seen in workshop #2. Note that there is, as expected, a strong interaction between time and treatment, i.e. PRL varies differently over time for different treatments.
- A correlation table. For most, if not all, of the situations you will be dealing with you can safely ignore this.
- A summary of the distribution of residuals
- The number of observations and groups. You can use this to check that you have correctly specified your experiment structure in the model. We have a total of 270 observations (you can check this by running `ncol(bromocriptine)`) and 45 groups (i.e. experimental units), corresponding to the 45 mice. This tells us that R has understood that those 270 observations are not independent, but come from 45 mice, therefore multiple observations are associated with the same mouse.

\newpage

We can check the distribution of residuals over the fitted values as usual (although the output has a slight different format compared to `lm`)

```{r}
plot(model, pch = 20)
```

Let's now explore the distribution of the random effects and compare it with that of the residuals. The `random.effects` function returns the random effects. We can combine it with hist and we can see that random effects come from a normal distribution, as expected, with a different variance as that of the residuals (notice the different x scale).

```{r echo = F}
par(mar = c(2, 4, 2, 2))
```

```{r, fig.height = 4.8}
head(random.effects(model))

par(mfrow = c(2, 1))
hist(random.effects(model)$Time, main = "", col = "black", 
     xlab = "Random effects", las = 1)
hist(resid(model), main = "", col = "black", xlab = "Residuals",
     las = 1)
```
```{r, echo = F}
par(mfrow = c(1, 1))
```

We can also check that R has correctly fitted a random slope model.

```{r, width = 80, size = "small"}
head(coef(model))
```

Note how all coefficients are the same for all the animals, but the slope for time has been changed for each animal. For instance, let's plot the data for mice 1 and 6. These are both control mice, but have quite different profiles.

```{r, fig.height = 3}
plot(PRL ~ Time, bromocriptine, subset = bromocriptine$Mouse == 1, 
     t = "l", las = 1, bty = "n")
lines(PRL ~ Time, bromocriptine, subset = bromocriptine$Mouse == 6, 
      col = "blue")
```

Indeed, looking at the fitted slopes, they are 3.96 and 1.91, while the intercept is 17.24 for both.

We can use `abline` to add those to the plot above.

```{r eval = F}
abline(17.24, 3.96, lty = "dashed")  # Mouse 1
abline(17.24, 1.91, lty = "dashed")  # Mouse 6
```

```{r echo = F, fig.height = 3}
plot(PRL ~ Time, bromocriptine, subset = bromocriptine$Mouse == 1, 
     t = "l", las = 1, bty = "n")
lines(PRL ~ Time, bromocriptine, subset = bromocriptine$Mouse == 6, 
      col = "blue")
abline(17.24, 3.96, lty = "dashed")
abline(17.24, 1.91, col = "blue", lty = "dashed")
```

Finally, let's use `emmeans` to compare the three different treatments. We use an extra argument here (`cov.reduce = range`) to tell emmeans to look at the range of the continuous variable time. If we do not use that, `emmeans` and `pairs` will make comparisons only at the mean time (that is, 75).

```{r warning = FALSE, message = FALSE, width = 80, size = "small"}
library(emmeans)

marginals <- emmeans(model, ~ Group * Time, cov.reduce = range)
pairs(marginals, by = "Time")

```

Our post-hoc analysis has revealed  that there is a significant difference between all of the groups at time 150, but not at time 0.
Should you want to test all of the times you could use `cov.reduce = unique`.


\newpage
# Nested design - a split plot experiment

We will now analyse a split plot experiment as an example of a nested design^[This example is taken from Pinheiro and Bates, 2000].

For this examples we will use the Oats dataset that comes with the `nlme` package (this is automatically loaded when you load `nlme`). 

These data comes from an example of split-plot design by Yates (1935). 

The treatment structure used in the experiment was a 3 x 4 full factorial, with three varieties of oats and four concentrations of nitrogen. The experimental units were arranged into six blocks, each with three whole-plots subdivided into four subplots. The varieties of oats were assigned randomly to the whole-plots and the concentrations of nitrogen to the subplots. All four concentrations of nitrogen were used on each whole-plot.

In this experiment we have six blocks of land, each of which is divided in 3 plots, each of which is further divided in 4 subplots.
In each plot we grow one variety of grain (chosen at random), and in each subplot we use a different nitrogen concentration (nitrogen is used as a fertiliser). Because we have 4 subplots, we use 4 different nitrogen concentrations. The varieties of grain are called Golden Rain, Marvellous and Victory. Our output variable is the yield of the specific plot.
This is a 3 x 4 full factorial design, meaning that each of the 3 variety was treated with each of the 4 nitrogen combinations (therefore it is "full", because all possible combinations are taken into account).

We ask whether 1) nitrogen has an effect on yield and 2) whether the different varieties give different yields 3) if there is an interaction between the two.

We start as usual by exploring and plotting the dataset

```{r size = "small", width = 80}
summary(Oats)
```

\newpage
You can produce several interesting plots with these data, and I encourage you to do so. This is a plot summarising the relationship between the different variables.

```{r echo = FALSE}
ggplot(aes(nitro, yield), group = Block, data = Oats) +
geom_line(aes(col = Block)) +
facet_wrap(~Variety) + 
xlab("Nitrogen concentration") +
ylab("Yield") +
theme(legend.position = "bottom")
```

We can see clear plot-to-plot differences, and it looks like yield grows approximatively linearly with nitrogen concentration.

We now need to think about what are the random effects and how they are nested. We have 6 blocks, each divided in 3 plots (one per variety) and each divided in 4 subplots (one per nitrogen concentration).
Because we only get one measure of yield from each subplot, we will not consider this as a random effect, but we will consider plots nested within blocks as our random effects.

Let's create our model!
```{r}
model.oats <- lme(yield ~ nitro * Variety, data = Oats, random = ~ 1 | Block/Variety)
```

Note that we have created a random intercept model (look at the graph above and think why we have done that!). Also, we are using Blocks and plots (we use Variety, since each plot is associated with a variety) as our random effects, nested within each other. Note that we list the larger factors first, then those contained within. If we had multiple levels of nesting we could indicate them using multiple / (e.g. City/School/Class)

Let's see the summary^[For a more concise output you can also do `anova(model.oats)`]
```{r size = "small", width = 80}
summary(model.oats)
```

We can see a clear effect of nitrogen, but not of variety, and no significant interactions.
Also, note that the output is slightly different from the previous example in that
- It tells us that there are 72 observations, from 18 plots (coded as Varieties) nested into 6 blocks.
- The standard deviations in the random effect part of the summary are for intercept and residual rather than slope and residual as before, since we are fitting a random intercept model.

Since the interaction terms are not significant we can drop them and get a simpler model

```{r width = 80, size = "small"}
model.oats.2 <- lme(yield ~ nitro + Variety, data = Oats, random = ~ 1 | Block/Variety)

summary(model.oats.2)
```

The conclusion from the simpler model are essentially the same: a significant effect of nitrogen but not of variety. Also, the estimations for the random effects have only had minimal changes (look at the standard deviations for residuals and for the intercept).

We can check that some the regressions make sense by plotting regression lines for different plots, just as we did before.

-----

We have only scratched the surface of how to use mixed-effects models, and there is a lot more to it. For the scope of this course what we have done is more than enough, but if you are interested there are a lot of resources around to become an expert in this topic!